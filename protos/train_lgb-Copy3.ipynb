{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17614600-d928-4269-b599-94238359ad66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import cv2\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae71b09-cdd2-41ef-b3f9-d001fb85af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "from tqdm.auto import tqdm\n",
    "if 0:\n",
    "    df1 = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv')\n",
    "    df1['path'] = '../input/petfinder-adoption-prediction/train_images/' + df1['PetID'] + '-1.jpg'\n",
    "    df1 = df1[df1['path'].map(os.path.exists)]\n",
    "\n",
    "    df2 = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\n",
    "    df2['path'] = df2['Id'].map(lambda x:str(f'../input/petfinder-pawpularity-score/train/{x}.jpg'))\n",
    "\n",
    "    df1['hash'] = [imagehash.average_hash(Image.open(x))\n",
    "                        for x in tqdm(df1['path'].values)]\n",
    "    df2['hash'] = [imagehash.average_hash(Image.open(x))\n",
    "                        for x in tqdm(df2['path'].values)]\n",
    "    #train_df_prev['hash'] = [imagehash.average_hash(Image.open(x))\n",
    "    #                    for x in tqdm(train_df_prev['path'].values)]\n",
    "\n",
    "    df1.to_csv('df1.csv', index=False)\n",
    "    df2.to_csv('df2.csv', index=False)\n",
    "else:\n",
    "    df1 = pd.read_csv('df1.csv')\n",
    "    df2 = pd.read_csv('df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49316dd6-c0f2-42a1-8281-f196f12d0e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14541, (14652, 26))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.hash.nunique(), df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c88b0a1-3236-432f-aae2-86c2fd5164eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import load_model\n",
    "    import tensorflow_similarity as tfsim\n",
    "    tfsim.utils.tf_cap_memory() # Avoid GPU memory blow up\n",
    "    IMG_SIZE = 300\n",
    "    BATCH_SIZE = 64\n",
    "    def load_and_preprocess_image(path):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "        return img\n",
    "\n",
    "    model = load_model('../../similarity/examples/sim.model')\n",
    "\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(df1.path.values)\n",
    "    ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    embeds1 = model.predict(ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(df2.path.values)\n",
    "    ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    embeds2 = model.predict(ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    from cuml.neighbors import NearestNeighbors\n",
    "\n",
    "    model = NearestNeighbors(n_neighbors=1, metric=\"cosine\")\n",
    "    model.fit(embeds1)\n",
    "    distances, indices = model.kneighbors(embeds2)\n",
    "\n",
    "    df2['distance'] = distances\n",
    "    df2['hash'] = indices\n",
    "    df2.loc[df2['distance'] < 1.0e-4, 'hash'] = -1\n",
    "    df1['hash'] = df1.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8808a1f-1264-40c5-b2cf-7511c7ac79fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14652, 26), 14541)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape, df1.hash.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ee841e1-cc98-4ede-b7b1-eb2b54207af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37485dbae40d473888ed8663ab7f3755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 0:\n",
    "    list_label = []\n",
    "    list_det = []\n",
    "    for path in tqdm(df2['path'].values):\n",
    "        #result = inference_detector(model, path)\n",
    "        #list_det.append(get_det_result(result))\n",
    "        image = cv2.imread(path)\n",
    "        list_label.append(image.shape)\n",
    "\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255\n",
    "\n",
    "        #image = cv2.resize(image, (240, 240))\n",
    "        #image = np.moveaxis(image, -1, 0)\n",
    "        #image = torch.tensor([image], dtype=torch.float32, device=device)\n",
    "        #list_label.append(model(image).cpu().numpy()[0].argmax())\n",
    "\n",
    "    #df['resnet_label'] = list_label\n",
    "    list_label = np.array(list_label)\n",
    "    df2['img_h'] = list_label[:, 0]\n",
    "    df2['img_w'] = list_label[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5794088a-5d70-494a-8a1f-d6b4fd126c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14652, 2175)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "model = TfidfVectorizer(stop_words=None,#np.load('stop_words.npy').tolist(),\n",
    "                            binary=False,\n",
    "                            #norm='l1',\n",
    "                            #analyzer='char_wb',\n",
    "                            #ngram_range=(2, 5),\n",
    "                            # tokenizer=tokenizer,\n",
    "                            # max_features=50000,\n",
    "                            #max_df=50,\n",
    "                            min_df=2,\n",
    "                            dtype=np.float32)\n",
    "\n",
    "#data = model.fit_transform(df1['Description'].fillna('').str.lower().values)\n",
    "#df1['desc_sum'] = np.array(data.sum(axis=1))[:, 0]\n",
    "#df1['desc_max'] = np.array(data.max(axis=1).todense())[:, 0]\n",
    "#df1['desc_mean'] = df1['desc_sum'] / (data.getnnz(axis=1))\n",
    "\n",
    "\n",
    "data = model.fit_transform(df1['Name'].fillna('').str.lower().values)\n",
    "print(data.shape)\n",
    "df1['name_sum'] = np.array(data.sum(axis=1))[:, 0]\n",
    "df1['name_max'] = np.array(data.max(axis=1).todense())[:, 0]\n",
    "df1['name_mean'] =  df1['name_sum'] / data.getnnz(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de1d1715-2230-43cc-8634-7ca65866af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab = ['abandoned', 'active', 'adopt', 'adopted', 'adoption', 'after', 'all', 'an', 'and', 'are', 'as', 'at', 'be', 'been', 'being', 'bring', 'but', 'by', 'call', 'can', 'care', 'cat', 'contact', 'cute', 'dog', 'family', 'for', 'forever', 'found', 'from', 'give', 'good', 'has', 'have', 'he', 'healthy', 'heavy', 'her', 'him', 'home', 'if', 'in', 'interested', 'is', 'it', 'likes', 'looking', 'loving', 'male', 'me', 'months', 'mother', 'must', 'my', 'new', 'no', 'not', 'of', 'old', 'on', 'or', 'other', 'out', 'playful', 'please', 'puppy', 'rescued', 'she', 'so', 'spayed', 'take', 'than', 'that', 'the', 'they', 'this', 'to', 'trained', 'vaccination', 'very', 'visit', 'was', 'we', 'well', 'whatsapp', 'who', 'will', 'with', 'would', 'you']\n",
    "vocab = ['active', 'adopt', 'adoption', 'all', 'an', 'and', 'are', 'as', 'at', 'be', 'bring', 'but', 'by', 'call', 'can', 'care', 'cat', 'contact', 'cute', 'dog', 'family', 'for', 'from', 'give', 'good', 'has', 'have', 'he', 'healthy', 'her', 'him', 'home', 'if', 'in', 'interested', 'is', 'it', 'looking', 'loving', 'me', 'must', 'my', 'no', 'not', 'of', 'old', 'on', 'or', 'playful', 'please', 'rescued', 'she', 'spayed', 'that', 'the', 'they', 'this', 'to', 'trained', 'very', 'was', 'we', 'whatsapp', 'will', 'with', 'you']\n",
    "#vocab = ['active', 'adopt', 'adoption', 'all', 'an', 'and', 'are', 'as', 'at', 'be', 'bring', 'but', 'by', 'can', 'care', 'cat', 'contact', 'cute', 'dog', 'family', 'for', 'give', 'good', 'has', 'have', 'he', 'healthy', 'her', 'him', 'home', 'if', 'in', 'interested', 'is', 'it', 'looking', 'loving', 'me', 'must', 'my', 'no', 'not', 'of', 'old', 'on', 'or', 'playful', 'please', 'rescued', 'she', 'spayed', 'that', 'the', 'they', 'this', 'to', 'trained', 'very', 'was', 'we', 'will', 'with', 'you']\n",
    "model = TfidfVectorizer(stop_words=None,#np.load('stop_words.npy').tolist(),\n",
    "                            binary=False,\n",
    "                            #norm='l1',\n",
    "                            #analyzer='char_wb',\n",
    "                            #ngram_range=(2, 5),\n",
    "                            # tokenizer=tokenizer,\n",
    "                            # max_features=50000,\n",
    "                            #max_df=50,\n",
    "                            #vocabulary=vocab,\n",
    "                            min_df=2,\n",
    "                            dtype=np.float32)\n",
    "\n",
    "tmp = df1['Description'].fillna('').str.lower()# + ' ' + df1['Name'].fillna('').str.lower() \n",
    "#data = model.fit_transform(df1['Description'].fillna('').str.lower().values)\n",
    "data = model.fit_transform(tmp.values)\n",
    "\n",
    "map_i2w = {v:k for k, v in model.vocabulary_.items()}\n",
    "#data = np.array(data.todense())\n",
    "\n",
    "if 1:\n",
    "    for w in vocab:\n",
    "        if w in model.vocabulary_:\n",
    "            df1[f'tfidf_{w}'] = np.array(data[:, model.vocabulary_[w]].todense())\n",
    "else:\n",
    "    for w, i in model.vocabulary_.items():\n",
    "        df1[f'tfidf_{w}'] = np.array(data[:, i].todense())\n",
    "    \n",
    "#for w in ['white', 'boy']:\n",
    "#    df1[f'tfidf_{w}'] = np.array(data[:, model.vocabulary_[w]].todense())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb12915-0b7b-41c0-81de-03dc792638e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9939, 112)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df1.to_csv('train_last_comp.csv', index=False)\n",
    "df1['hash'] = df1['hash'].astype(str)\n",
    "df2['hash'] = df2['hash'].astype(str)\n",
    "df = pd.merge(df2, df1, how='left', on='hash')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8224255-2073-40c0-86e0-23de607be00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len_desc'] = df['Description'].fillna('').map(len)\n",
    "df['len_word_desc'] = df['Description'].fillna('').map(lambda x: len(x.split()))\n",
    "for n in ['No Name Yet']:#, 'No Name', 'Unknown']:\n",
    "    df['Name'] = df['Name'].fillna('').replace(n, '')\n",
    "df['len_name'] = df['Name'].map(len)\n",
    "df['len_word_name'] = df['Name'].fillna('').map(lambda x: len(x.split()))\n",
    "\n",
    "df['cnt_RescuerID'] = df['RescuerID'].map(df1['RescuerID'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "158e843a-9e34-4773-9b77-c0c907d9ee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../exps/exp1_swin_large_patch4_window12_384/train_cv_score.csv')\n",
    "#df = pd.read_csv('ens_exp15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7dbb7d2-d233-4734-998b-b07edff10eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.471986\n",
       "1       0.402806\n",
       "2       0.440848\n",
       "3       0.603114\n",
       "4       0.386127\n",
       "          ...   \n",
       "9934    0.276084\n",
       "9935    0.371682\n",
       "9936    0.293679\n",
       "9937    0.469386\n",
       "9938    0.434194\n",
       "Name: pred, Length: 9939, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pred'] = df['path_x'].map(pd.read_csv('ens_exp15.csv', index_col='path')['pred'])\n",
    "df['pred'] += df['path_x'].map(pd.read_csv('ens_exp9.csv', index_col='path')['pred'])\n",
    "df['pred'] /= 2\n",
    "df['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee4709c1-b656-4854-abf2-28b3fd48fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    from transformers import pipeline, AutoTokenizer\n",
    "    model_name = \"bert-base-multilingual-uncased\"\n",
    "    #tokenizer = AutoTokenizer.from_pretrained(model_name, max_length=512)\n",
    "    feature_extraction = pipeline('feature-extraction', model=model_name, tokenizer=model_name, padding=True, truncation=True, device=0)\n",
    "    features = feature_extraction(df['Name'].fillna('').str.lower().values.tolist())\n",
    "    #features = feature_extraction(df['Description'].fillna('').str.lower().values.tolist())\n",
    "\n",
    "    data = np.stack([np.mean(f[0], axis=0) for f in features])\n",
    "    for i in range(data.shape[1]):\n",
    "        df[f'bert_{i}'] = data[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bc968c2-28f2-4a04-b308-10456dfd1482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "df['fold'] = -1\n",
    "\n",
    "\n",
    "N_FOLDS = 5\n",
    "strat_kfold = StratifiedKFold(n_splits=5, random_state=365, shuffle=True)\n",
    "for i, (_, train_index) in enumerate(strat_kfold.split(df.index, df['Pawpularity'])):\n",
    "    df.loc[train_index, 'fold'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7853b4fd-f063-41f0-ab2f-9c3292b93f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_FEATURES = ['Blur', \n",
    "                #'Face', \n",
    "                #'Occlusion',\n",
    "                'Eyes',\n",
    "                #'Accessory',\n",
    "               #'Group',\n",
    "                #'Human',\n",
    "                #'Near',\n",
    "                #'Collage',\n",
    "                #'Info',# \n",
    "                #'Action',\n",
    "                \n",
    "                'pred',\n",
    "                \n",
    "                'len_desc', 'len_name',\n",
    "                #'breed_label',# 'breed_prob',\n",
    "                #'len_word_desc', 'len_word_name',\n",
    "                #'isin'\n",
    "                #'breed_label', 'breed_prob',\n",
    "                'img_h', 'img_w',\n",
    "                #'det_label', 'det_left', 'det_top', 'det_right', 'det_bottom', 'det_prob'\n",
    "               ] + df1.drop(['Name', 'RescuerID', 'Description', 'PetID', 'path', 'hash',\n",
    "                             'Type', 'VideoAmt', 'Sterilized', 'MaturitySize', 'Health', 'Dewormed',# 'Breed1'\n",
    "                            ], axis=1).columns.tolist() + [c for c in df.columns if 'bert_' in c]\n",
    "\n",
    "#COL_FEATURES = COL_FEATURES[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06c985aa-3d6f-4e9f-b33f-ed34b6408263",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df['Pawpularity'].values.min() == 0:\n",
    "    df['Pawpularity'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa350009-717a-4737-a6f3-9ee1fd900de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    #import pdb;pdb.set_trace()\n",
    "    loss = np.sqrt(((labels - preds.clip(0.01, 1)) ** 2).mean()) * 100\n",
    "    \n",
    "    #loss = np.sqrt(((labels - preds.reshape(-1, 100).argmax(axis=1)) ** 2).mean())\n",
    "    return 'rmse', loss, False\n",
    "\n",
    "\n",
    "def train(fold, param):\n",
    "     \n",
    "    X_train = df.loc[df['fold'] != fold, COL_FEATURES]\n",
    "    y_train = df.loc[df['fold'] != fold, 'Pawpularity'].values  / 100\n",
    "    \n",
    "    X_valid = df.loc[df['fold'] == fold, COL_FEATURES]\n",
    "    y_valid = df.loc[df['fold'] == fold, 'Pawpularity'].values  / 100\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "    \n",
    "    model = lgb.train(param,\n",
    "                      train_data,\n",
    "                      valid_sets=valid_data,\n",
    "                      #early_stopping_rounds=50,\n",
    "                      verbose_eval=1000,\n",
    "                      feval=rmse\n",
    "                      )\n",
    "    return model\n",
    "\n",
    "def train_all(param):\n",
    "     \n",
    "    X_train = df.loc[:, COL_FEATURES]\n",
    "    y_train = df.loc[:, 'Pawpularity'].values  / 100\n",
    "    \n",
    "    X_valid = df.loc[:, COL_FEATURES]\n",
    "    y_valid = df.loc[:, 'Pawpularity'].values  / 100\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "    \n",
    "    model = lgb.train(param,\n",
    "                      train_data,\n",
    "                      valid_sets=valid_data,\n",
    "                      early_stopping_rounds=50,\n",
    "                      verbose_eval=1000,\n",
    "                      feval=rmse\n",
    "                      )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd671d69-c6ee-4881-a5c9-a87de117e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = {'objective': ['tweedie'],\n",
    "              'tweedie_variance_power': [1.2],\n",
    "             'verbosity': [-1],\n",
    "             'boosting_type': ['gbdt'],\n",
    "             'feature_pre_filter': [False],\n",
    "             #'bagging_fraction': [0.7, 0.8, 0.9, 1],\n",
    "             'bagging_freq': [1],\n",
    "             'num_iterations': [10000],\n",
    "             'early_stopping_round': [100],\n",
    "             'n_jobs': [16],\n",
    "             'seed': [114],\n",
    "             'metric':  ['None'],  # trial.suggest_categorical('metric', ['auc', 'binary_logloss', ]), #'auc',\n",
    "             'learning_rate': [0.05],\n",
    "              'lambda_l1': [0],\n",
    "              'lambda_l2': [1],\n",
    "              'min_child_samples': [170],\n",
    "              'num_leaves': [7],\n",
    "              'feature_fraction': [0.8],\n",
    "              'min_gain_to_split': [0.02],\n",
    "              'linear_tree': [False],\n",
    "              #'max_bins': [8, 16, 32, 62, 128, 256, 512]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb9d4d7f-6a80-46d3-99dd-8577a97a2189",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3115eea3c84ab78ca51584bc575ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_freq': 1, 'boosting_type': 'gbdt', 'early_stopping_round': 100, 'feature_fraction': 0.8, 'feature_pre_filter': False, 'lambda_l1': 0, 'lambda_l2': 1, 'learning_rate': 0.05, 'linear_tree': False, 'metric': 'None', 'min_child_samples': 170, 'min_gain_to_split': 0.02, 'n_jobs': 16, 'num_iterations': 10000, 'num_leaves': 7, 'objective': 'tweedie', 'seed': 114, 'tweedie_variance_power': 1.2, 'verbosity': -1}\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's rmse: 17.1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's rmse: 17.1653\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's rmse: 17.3397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's rmse: 17.1704\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's rmse: 16.7856\n"
     ]
    }
   ],
   "source": [
    "best_score = 1.0e10\n",
    "best_param = None\n",
    "for param in tqdm(ParameterGrid(all_params)):\n",
    "    print(param)\n",
    "    list_loss = []\n",
    "    list_imp = []\n",
    "    list_num = []\n",
    "    for fold in range(5):\n",
    "        model = train(fold, param)\n",
    "        sc = model.best_score['valid_0']['rmse']# * 100\n",
    "        list_loss.append(sc)\n",
    "        list_num.append(model.best_iteration)\n",
    "        \n",
    "        imp = pd.DataFrame(model.feature_importance(importance_type='gain'), columns=['imp'])\n",
    "        imp['col'] = COL_FEATURES\n",
    "        list_imp.append(imp.set_index('col'))\n",
    "    sc = np.mean(list_loss)\n",
    "    if sc < best_score:\n",
    "        best_score = sc\n",
    "        best_param = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67f04282-698e-499c-8a9a-37686c5f1a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_freq': 1, 'boosting_type': 'gbdt', 'early_stopping_round': 100, 'feature_fraction': 0.8, 'feature_pre_filter': False, 'lambda_l1': 0, 'lambda_l2': 1, 'learning_rate': 0.05, 'linear_tree': False, 'metric': 'None', 'min_child_samples': 170, 'min_gain_to_split': 0.02, 'n_jobs': 16, 'num_iterations': 10000, 'num_leaves': 7, 'objective': 'tweedie', 'seed': 114, 'tweedie_variance_power': 1.2, 'verbosity': -1}\n",
      "17.126018982016205\n"
     ]
    }
   ],
   "source": [
    "17.122953793907463\n",
    "17.12237161917507\n",
    "17.12206798235878\n",
    "17.118772493988214\n",
    "17.11253518980743\n",
    "17.10951939364919\n",
    "17.10667371043545\n",
    "print(best_param)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81ed8bf9-c750-4e4d-85d7-3a71292422b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param['num_iterations'] = round(np.mean(list_num) * 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cca590f-49d1-49e0-8ef8-f02a32067004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[201]\tvalid_0's rmse: 16.6721\n"
     ]
    }
   ],
   "source": [
    "model = train_all(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f98a767-4ac0-49e9-b040-073f23770ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.275769284357725"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = 0\n",
    "for i in range(5):\n",
    "    aaa += np.sqrt(((df.loc[df['fold']==i, 'pred'] * 100 - df.loc[df['fold']==i, 'Pawpularity']) ** 2).mean())\n",
    "aaa / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e43a7add-0935-4645-93f2-e283bc54cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/model_lgb_last_comp_all.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a3d00a0-a4cd-4955-89c2-3f4f9940c0a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <td>3088.936279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breed1</th>\n",
       "      <td>56.815157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>15.379413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_w</th>\n",
       "      <td>15.110815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhotoAmt</th>\n",
       "      <td>14.319040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_is</th>\n",
       "      <td>14.245327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <td>12.965359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_h</th>\n",
       "      <td>12.604309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_max</th>\n",
       "      <td>12.478088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blur</th>\n",
       "      <td>11.995609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eyes</th>\n",
       "      <td>11.110168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_to</th>\n",
       "      <td>7.723255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breed2</th>\n",
       "      <td>7.576640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_name</th>\n",
       "      <td>7.265206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_desc</th>\n",
       "      <td>7.139993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_the</th>\n",
       "      <td>7.122054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>6.943375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_mean</th>\n",
       "      <td>6.608698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_and</th>\n",
       "      <td>6.550603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vaccinated</th>\n",
       "      <td>6.116497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_of</th>\n",
       "      <td>6.068059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FurLength</th>\n",
       "      <td>5.745499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_they</th>\n",
       "      <td>4.564994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantity</th>\n",
       "      <td>4.388829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_for</th>\n",
       "      <td>3.603087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_as</th>\n",
       "      <td>3.582102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_sum</th>\n",
       "      <td>3.366895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_this</th>\n",
       "      <td>3.349316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_please</th>\n",
       "      <td>3.253825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color2</th>\n",
       "      <td>3.015177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_not</th>\n",
       "      <td>2.997028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_home</th>\n",
       "      <td>2.962380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_cat</th>\n",
       "      <td>2.604891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color3</th>\n",
       "      <td>2.526307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_it</th>\n",
       "      <td>2.463629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_with</th>\n",
       "      <td>2.440814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_be</th>\n",
       "      <td>2.353122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_very</th>\n",
       "      <td>1.928939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_you</th>\n",
       "      <td>1.877610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_will</th>\n",
       "      <td>1.837611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_her</th>\n",
       "      <td>1.780395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>1.748600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_can</th>\n",
       "      <td>1.518017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_was</th>\n",
       "      <td>1.483566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_if</th>\n",
       "      <td>1.456807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_adoption</th>\n",
       "      <td>1.430291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_looking</th>\n",
       "      <td>1.252724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color1</th>\n",
       "      <td>1.248855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_but</th>\n",
       "      <td>1.134253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_in</th>\n",
       "      <td>1.044997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_playful</th>\n",
       "      <td>0.939085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_interested</th>\n",
       "      <td>0.931439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_has</th>\n",
       "      <td>0.868732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_give</th>\n",
       "      <td>0.822060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fee</th>\n",
       "      <td>0.745295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_contact</th>\n",
       "      <td>0.726928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_my</th>\n",
       "      <td>0.657266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_by</th>\n",
       "      <td>0.641757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_are</th>\n",
       "      <td>0.604928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_loving</th>\n",
       "      <td>0.602139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_healthy</th>\n",
       "      <td>0.559358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_she</th>\n",
       "      <td>0.503191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_care</th>\n",
       "      <td>0.438848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_rescued</th>\n",
       "      <td>0.432509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_trained</th>\n",
       "      <td>0.429155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_must</th>\n",
       "      <td>0.355694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_on</th>\n",
       "      <td>0.352734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_cute</th>\n",
       "      <td>0.351512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_old</th>\n",
       "      <td>0.350591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_whatsapp</th>\n",
       "      <td>0.340585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_me</th>\n",
       "      <td>0.332835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_him</th>\n",
       "      <td>0.293827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_or</th>\n",
       "      <td>0.255633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_have</th>\n",
       "      <td>0.221800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_that</th>\n",
       "      <td>0.210468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_dog</th>\n",
       "      <td>0.182887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_adopt</th>\n",
       "      <td>0.170509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_bring</th>\n",
       "      <td>0.155526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_no</th>\n",
       "      <td>0.137911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_all</th>\n",
       "      <td>0.118638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_spayed</th>\n",
       "      <td>0.106334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_at</th>\n",
       "      <td>0.099792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_he</th>\n",
       "      <td>0.096330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_family</th>\n",
       "      <td>0.075013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_active</th>\n",
       "      <td>0.040036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_good</th>\n",
       "      <td>0.036943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_we</th>\n",
       "      <td>0.023866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_call</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_from</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf_an</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          imp\n",
       "col                          \n",
       "pred              3088.936279\n",
       "Breed1              56.815157\n",
       "Age                 15.379413\n",
       "img_w               15.110815\n",
       "PhotoAmt            14.319040\n",
       "tfidf_is            14.245327\n",
       "AdoptionSpeed       12.965359\n",
       "img_h               12.604309\n",
       "name_max            12.478088\n",
       "Blur                11.995609\n",
       "Eyes                11.110168\n",
       "tfidf_to             7.723255\n",
       "Breed2               7.576640\n",
       "len_name             7.265206\n",
       "len_desc             7.139993\n",
       "tfidf_the            7.122054\n",
       "State                6.943375\n",
       "name_mean            6.608698\n",
       "tfidf_and            6.550603\n",
       "Vaccinated           6.116497\n",
       "tfidf_of             6.068059\n",
       "FurLength            5.745499\n",
       "tfidf_they           4.564994\n",
       "Quantity             4.388829\n",
       "tfidf_for            3.603087\n",
       "tfidf_as             3.582102\n",
       "name_sum             3.366895\n",
       "tfidf_this           3.349316\n",
       "tfidf_please         3.253825\n",
       "Color2               3.015177\n",
       "tfidf_not            2.997028\n",
       "tfidf_home           2.962380\n",
       "tfidf_cat            2.604891\n",
       "Color3               2.526307\n",
       "tfidf_it             2.463629\n",
       "tfidf_with           2.440814\n",
       "tfidf_be             2.353122\n",
       "tfidf_very           1.928939\n",
       "tfidf_you            1.877610\n",
       "tfidf_will           1.837611\n",
       "tfidf_her            1.780395\n",
       "Gender               1.748600\n",
       "tfidf_can            1.518017\n",
       "tfidf_was            1.483566\n",
       "tfidf_if             1.456807\n",
       "tfidf_adoption       1.430291\n",
       "tfidf_looking        1.252724\n",
       "Color1               1.248855\n",
       "tfidf_but            1.134253\n",
       "tfidf_in             1.044997\n",
       "tfidf_playful        0.939085\n",
       "tfidf_interested     0.931439\n",
       "tfidf_has            0.868732\n",
       "tfidf_give           0.822060\n",
       "Fee                  0.745295\n",
       "tfidf_contact        0.726928\n",
       "tfidf_my             0.657266\n",
       "tfidf_by             0.641757\n",
       "tfidf_are            0.604928\n",
       "tfidf_loving         0.602139\n",
       "tfidf_healthy        0.559358\n",
       "tfidf_she            0.503191\n",
       "tfidf_care           0.438848\n",
       "tfidf_rescued        0.432509\n",
       "tfidf_trained        0.429155\n",
       "tfidf_must           0.355694\n",
       "tfidf_on             0.352734\n",
       "tfidf_cute           0.351512\n",
       "tfidf_old            0.350591\n",
       "tfidf_whatsapp       0.340585\n",
       "tfidf_me             0.332835\n",
       "tfidf_him            0.293827\n",
       "tfidf_or             0.255633\n",
       "tfidf_have           0.221800\n",
       "tfidf_that           0.210468\n",
       "tfidf_dog            0.182887\n",
       "tfidf_adopt          0.170509\n",
       "tfidf_bring          0.155526\n",
       "tfidf_no             0.137911\n",
       "tfidf_all            0.118638\n",
       "tfidf_spayed         0.106334\n",
       "tfidf_at             0.099792\n",
       "tfidf_he             0.096330\n",
       "tfidf_family         0.075013\n",
       "tfidf_active         0.040036\n",
       "tfidf_good           0.036943\n",
       "tfidf_we             0.023866\n",
       "tfidf_call           0.000000\n",
       "tfidf_from           0.000000\n",
       "tfidf_an             0.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imp = pd.DataFrame(model.feature_importance(importance_type='gain'), columns=['imp'])\n",
    "#imp['col'] = COL_FEATURES\n",
    "pd.options.display.max_rows = 3000\n",
    "imp = sum(list_imp) / 5\n",
    "#imp = imp[imp.imp > 0]\n",
    "imp.sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8ce748a-2d6a-490b-85a8-0f4f82cad39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['active', 'adopt', 'adoption', 'all', 'an', 'and', 'are', 'as', 'at', 'be', 'bring', 'but', 'by', 'call', 'can', 'care', 'cat', 'contact', 'cute', 'dog', 'family', 'for', 'from', 'give', 'good', 'has', 'have', 'he', 'healthy', 'her', 'him', 'home', 'if', 'in', 'interested', 'is', 'it', 'looking', 'loving', 'me', 'must', 'my', 'no', 'not', 'of', 'old', 'on', 'or', 'playful', 'please', 'rescued', 'she', 'spayed', 'that', 'the', 'they', 'this', 'to', 'trained', 'very', 'was', 'we', 'whatsapp', 'will', 'with', 'you']\n"
     ]
    }
   ],
   "source": [
    "print([c[6:] for c in imp.index if 'tfidf_' in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb92f49a-52c1-4c24-b0ac-f6350c3f751b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print([c for c in imp.index if 'tfidf_name_' in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b41f27a-0dc8-4f76-acee-3cdc28fa9562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       102\n",
       "1       601\n",
       "2        88\n",
       "3         0\n",
       "4         0\n",
       "       ... \n",
       "9934      0\n",
       "9935      0\n",
       "9936      0\n",
       "9937    157\n",
       "9938      0\n",
       "Name: len_desc, Length: 9939, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.len_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b721e93b-6d0a-4be5-a713-c2357bd79578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blur',\n",
       " 'Eyes',\n",
       " 'pred',\n",
       " 'len_desc',\n",
       " 'len_name',\n",
       " 'img_h',\n",
       " 'img_w',\n",
       " 'Age',\n",
       " 'Breed1',\n",
       " 'Breed2',\n",
       " 'Gender',\n",
       " 'Color1',\n",
       " 'Color2',\n",
       " 'Color3',\n",
       " 'FurLength',\n",
       " 'Vaccinated',\n",
       " 'Quantity',\n",
       " 'Fee',\n",
       " 'State',\n",
       " 'PhotoAmt',\n",
       " 'AdoptionSpeed',\n",
       " 'name_sum',\n",
       " 'name_max',\n",
       " 'name_mean',\n",
       " 'tfidf_active',\n",
       " 'tfidf_adopt',\n",
       " 'tfidf_adoption',\n",
       " 'tfidf_all',\n",
       " 'tfidf_an',\n",
       " 'tfidf_and',\n",
       " 'tfidf_are',\n",
       " 'tfidf_as',\n",
       " 'tfidf_at',\n",
       " 'tfidf_be',\n",
       " 'tfidf_bring',\n",
       " 'tfidf_but',\n",
       " 'tfidf_by',\n",
       " 'tfidf_call',\n",
       " 'tfidf_can',\n",
       " 'tfidf_care',\n",
       " 'tfidf_cat',\n",
       " 'tfidf_contact',\n",
       " 'tfidf_cute',\n",
       " 'tfidf_dog',\n",
       " 'tfidf_family',\n",
       " 'tfidf_for',\n",
       " 'tfidf_from',\n",
       " 'tfidf_give',\n",
       " 'tfidf_good',\n",
       " 'tfidf_has',\n",
       " 'tfidf_have',\n",
       " 'tfidf_he',\n",
       " 'tfidf_healthy',\n",
       " 'tfidf_her',\n",
       " 'tfidf_him',\n",
       " 'tfidf_home',\n",
       " 'tfidf_if',\n",
       " 'tfidf_in',\n",
       " 'tfidf_interested',\n",
       " 'tfidf_is',\n",
       " 'tfidf_it',\n",
       " 'tfidf_looking',\n",
       " 'tfidf_loving',\n",
       " 'tfidf_me',\n",
       " 'tfidf_must',\n",
       " 'tfidf_my',\n",
       " 'tfidf_no',\n",
       " 'tfidf_not',\n",
       " 'tfidf_of',\n",
       " 'tfidf_old',\n",
       " 'tfidf_on',\n",
       " 'tfidf_or',\n",
       " 'tfidf_playful',\n",
       " 'tfidf_please',\n",
       " 'tfidf_rescued',\n",
       " 'tfidf_she',\n",
       " 'tfidf_spayed',\n",
       " 'tfidf_that',\n",
       " 'tfidf_the',\n",
       " 'tfidf_they',\n",
       " 'tfidf_this',\n",
       " 'tfidf_to',\n",
       " 'tfidf_trained',\n",
       " 'tfidf_very',\n",
       " 'tfidf_was',\n",
       " 'tfidf_we',\n",
       " 'tfidf_whatsapp',\n",
       " 'tfidf_will',\n",
       " 'tfidf_with',\n",
       " 'tfidf_you']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_name()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
